{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielleRab/SRMPmachine/blob/main/Decision_Trees_Exoplanets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg16fWNG_ioj"
      },
      "source": [
        "# **Exploring Exoplanets with Decision Trees** \n",
        "\n",
        "### **Step 1:** Identify your question\n",
        "\n",
        "In this colab, you will build a machine learning model to figure out which characteristics of an exoplanet are best correlated with its detection method. Put another way, which kinds of exoplanets can we find using each method of detection? \n",
        "\n",
        "For the sake of simplicity, let's focus on Radial Velocity and Transit, two of the most common means of exoplanet detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEVDmRuIDesI"
      },
      "source": [
        "### **Step 2:** Select your data\n",
        "\n",
        "The dataset for this activity came from the NASA Exoplanet Archive and is a composite of data from several different sources.\n",
        "\n",
        "We will be looking at a number of features of exoplanets. Here is a definition of each column in the dataset:\n",
        "\n",
        "*   pl_name: Planet Name\n",
        "*   discoverymethod: Discovery Method\n",
        "*   disc_year: Discovery Year\n",
        "*   pl_orbper:      Orbital Period [days]\n",
        "*   pl_orbsmax:     Orbit Semi-Major Axis [au]\n",
        "*   pl_radj:        Planet Radius [Jupiter Radius]\n",
        "*   pl_bmassj:      Planet Mass or Mass*sin(i) [Jupiter Mass]\n",
        "*   pl_bmassprov:   Planet Mass or Mass*sin(i) Provenance\n",
        "*   st_teff:        Stellar Effective Temperature [K]\n",
        "*   st_rad:         Stellar Radius [Solar Radius]\n",
        "*   st_mass:        Stellar Mass [Solar mass]\n",
        "*   sy_dist:        Distance [pc]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_CkpMjbxtmX"
      },
      "source": [
        "Let's load the data into the colab and take a look. Run the cell below to create a dataframe (table) of our data and preview the first five rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l3JLv18DaDg"
      },
      "outputs": [],
      "source": [
        "# import the necessary Python libraries\n",
        "import pandas as pd\n",
        "\n",
        "# create a dataframe called \"df\" with the dataset\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/GabrielleRab/SRMPmachine/main/datasets/exoplanets_cleaned.csv\")\n",
        "\n",
        "# preview the first five rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O-e1Lpr0P0B"
      },
      "source": [
        "The \"discoverymethod\" column contains the labels for this dataset. It tells us in advance which detection method was used for each exoplanet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8tqBQAhzy73"
      },
      "source": [
        "Run the code below to find out how many rows are in our dataset. Each row represents an exoplanet that has been identified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rP0ExL5zxnt"
      },
      "outputs": [],
      "source": [
        "# return the number of rows in the dataset\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DO64X0aET2F"
      },
      "source": [
        "### **Step 3:** Choose your method\n",
        "\n",
        "We will be using the Decision Tree method today, as it is a good fit for categorizing labeled data.\n",
        "\n",
        "Run the code below to import the necessary Python libraries for creating Decision Trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7BtJ4Td0qlQ"
      },
      "outputs": [],
      "source": [
        "#import necessary Python libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import graphviz\n",
        "from numpy.ma.extras import unique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQd76u9wbIoO"
      },
      "source": [
        "### **Step 4:** Prepare your data\n",
        "\n",
        "Decision Trees work best when the features being analyzed are numerical. Aside from our labels (\"discoverymethod\"), there are two columns that we need to address: \"pl_name\" and \"pl_bmassprov\".\n",
        "\n",
        "\"pl_name\" is easy to deal with. There aren't any meaningful binary questions we can ask about the planet's name, so let's remove that column. Run the code below to do so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoYfvbw4cUOa"
      },
      "outputs": [],
      "source": [
        "#We will remove columns we don't need for this investigation\n",
        "df = df.drop('pl_name', 1)\n",
        "\n",
        "#Return the first 5 rows of the dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gwrV-wc14nc"
      },
      "source": [
        "Next, let's address the \"pl_bmassprov\" column. This feature is actually very useful for us, as it indicates whether or not inclination was used to calculate the mass for the exoplanet. Certain detection methods include inclination while others don't.\n",
        "\n",
        "Instead of deleting the column, let's convert the feature into a binary value: 0 if the mass calculation method does not include inclination and 1 if it does. Run the code below to make this change:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YofobnCo13nA"
      },
      "outputs": [],
      "source": [
        "#Change pl_bmassprov column to 0 for exoplanets whose mass was not calculated\n",
        "#using inclination and 1 for those where it was used\n",
        "df['pl_bmassprov'] = df['pl_bmassprov'].map({'Mass': 0, 'M-R relationship': 0,\n",
        "                                             'Msin(i)/sin(i)': 1, 'Msini': 1})\n",
        "\n",
        "#Return the first 5 rows of the dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_ptjrAi2c0N"
      },
      "source": [
        "The next concern is that some rows in this dataset might be missing values for certain features. \n",
        "\n",
        "The code to create the model won't work if it can't find information for each feature for each exoplanet so we need to address this, either by removing the rows with missing values or by removing the columns where those missing values are found.\n",
        "\n",
        "In some cases, the absence of a value can tell us something. For example, some exoplanets don't have any value listed for orbital period. What discovery method do you think was used to find those? Run the code below to find out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZIkNiGVbxdf"
      },
      "outputs": [],
      "source": [
        "#Create a dataframe containing only the rows with no orbital period\n",
        "df_no_orb = df[df['pl_orbper'].isnull()]\n",
        "\n",
        "#Return the first 10 rows of that dataframe\n",
        "df_no_orb.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep52vMKU3OqZ"
      },
      "source": [
        "These exoplanets were primarily detected using the Imaging method. \n",
        "\n",
        "We'll be focusing on the Transit and Radial Velocity detection methods today, so we can remove these rows, but if we wanted to find exoplanets discovered using direct imaging we might want to remove the orbital period column instead. Otherwise, we would accidentally remove an entire subset of our data we wanted to study.\n",
        "\n",
        "Since we aren't worried about preserving any of the information from missing values, we can remove all of the rows with anything missing. Run the code below to do so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-o6tx7Ndv2Z"
      },
      "outputs": [],
      "source": [
        "#Remove any rows with missing values\n",
        "df = df.dropna()\n",
        "\n",
        "#Return the remaining number of rows\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HFLL80Q49Zd"
      },
      "source": [
        "We just removed 461 rows from our dataset, leaving only exoplanets with values for each feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyVG16bv3xKB"
      },
      "source": [
        "Finally, we can remove any rows from the dataset where detection methods other than Radial Velocity and Transit were used. Run the code below to do so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msFwMdGCh-M5"
      },
      "outputs": [],
      "source": [
        "#Remove exoplanets detected using Transit Timing Variations\n",
        "df = df.drop(df[df[\"discoverymethod\"].str.contains('Transit Timing Variations')].index)\n",
        "\n",
        "#Remove all other exoplanets discovered by methods other than RV or Transit\n",
        "df = df.drop(df[df[\"discoverymethod\"].str.contains('Radial Velocity|Transit')==False].index)\n",
        "\n",
        "#Return the current number of rows in the dataset\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIBWxxAe6H9W"
      },
      "source": [
        "Only 35 exoplanets in our cleaned dataset were detected using methods other than Radial Velocity or Transit. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvu0MXEF6TKR"
      },
      "source": [
        "Now that our dataset is ready, let's check it for balance. Are there the same number of exoplanets detected using each method? Run the code below to find out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJCwwfWOeovg"
      },
      "outputs": [],
      "source": [
        "#Return the number of rows with either Radial Velocity or Transit for discovery method\n",
        "print(\"Radial Velocity:\",len(df[df.discoverymethod == 'Radial Velocity']))\n",
        "print(\"Transit:\",len(df[df.discoverymethod == 'Transit']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMMJgjEm6jPA"
      },
      "source": [
        "As it turns out, there are significantly more exoplanets discovered using Transit than Radial Velocity. \n",
        "\n",
        "**Bias Alert:** This introduces a possible source of statistical bias into our analysis. Our decision tree may end up better prepared to identify exoplanets detected using Transit than Radial Velocity because it has more information about them.\n",
        "\n",
        "One way to address this source of bias is to ensure that our training and testing data both contain enough exoplanets detected using Radial Velocity. Another is to make sure that we have a large enough training dataset to include sufficient exoplanets detected using Radial Velocity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC0k603a8n7R"
      },
      "source": [
        "Now it's time to split our data into a training and a testing dataset. \n",
        "\n",
        "**Bias Alert:** If we split our data 50/50 and we see a difference in the number of exoplanets detected by each method in the two halves, it's a sign that our data is sorted.\n",
        "\n",
        "Run the code below to check:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a dataframe with the first half of our data\n",
        "df_first = df[0:2214]\n",
        "\n",
        "#Create a dataframe with the second half of our data\n",
        "df_last = df[2214:4429]\n",
        "\n",
        "#Return the number of exoplanets detected using each method for both halves\n",
        "print(\"First Half\")\n",
        "print(\"Radial Velocity:\",len(df_first[df_first.discoverymethod == 'Radial Velocity']))\n",
        "print(\"Transit:\",len(df_first[df_first.discoverymethod == 'Transit']))\n",
        "print(\"\")\n",
        "print(\"Second Half\")\n",
        "print(\"Radial Velocity:\",len(df_last[df_last.discoverymethod == 'Radial Velocity']))\n",
        "print(\"Transit:\",len(df_last[df_last.discoverymethod == 'Transit']))"
      ],
      "metadata": {
        "id": "xEZG7dGT_TVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset is significantly unbalanced. Not only are there more exoplanets detected using Transit than Radial Velocity, but our data was also sorted.\n",
        "\n",
        "We can address this issue by creating a random split instead. Run the code below to do so:"
      ],
      "metadata": {
        "id": "2wQpoLZG_7vn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfNcjA8rLWbe"
      },
      "outputs": [],
      "source": [
        "#Get the features and labels from the data \n",
        "x = df.drop(['discoverymethod'], axis=1)\n",
        "y = df['discoverymethod']\n",
        "\n",
        "#Specify a 50% split\n",
        "training_percentage = 50 \n",
        "\n",
        "#Create the training and testing datasets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, train_size=training_percentage/100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg2O6Ty-Mp9G"
      },
      "source": [
        "### **Step 5:** Train the model\n",
        "\n",
        "Now it's time to make our decision tree. We will also need to set the hyperparameters (values that control how the model learns and makes decisions). In this case we will specify the maximum depth and the criterion the model will use to evaluate each feature. \n",
        "\n",
        "The \"Gini index\" is a measure of how pure the split is for each node in the Decision Tree. A lower Gini index indicates a more pure split.\n",
        "\n",
        "Run the code below to create your model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8Z877SLNSx3"
      },
      "outputs": [],
      "source": [
        "#Create a decision tree classifier called \"clf\"\n",
        "clf = DecisionTreeClassifier(criterion='gini', max_depth=2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxZowIOUOjmj"
      },
      "source": [
        "Now that we have created a decision tree it's time to train it using our training dataset. We will also evaluate the model's accuracy (what percent of exoplanets did it correctly classify based on discovery method).\n",
        "\n",
        "Run the code below to train and evaluate our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNVwoVZlOkAU"
      },
      "outputs": [],
      "source": [
        "#Train the model\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "#Print the training accuracy \n",
        "print('\\nTraining Accuracy (%): ',(100*(clf.score(X_train,Y_train))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bias alert:** Because our training accuracy is so high, we run the risk of overfitting our model. This means it might be better at predicting the training data than the testing data.\n",
        "\n",
        "We can try to address this by training the model with a few different split percentages (instead of a 50/50 train/test split). Run the code below to see how they compare:"
      ],
      "metadata": {
        "id": "ooIT8KM9BbHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train and test the model with a 40% training percentage\n",
        "X_train_b, X_test_b, Y_train_b, Y_test_b = train_test_split(x, y, train_size=40/100)\n",
        "clf_b = DecisionTreeClassifier(criterion='gini', max_depth=2)\n",
        "clf_b.fit(X_train, Y_train)\n",
        "print('Training Accuracy (%) for 40/60 split: ',(100*(clf_b.score(X_train_b,Y_train_b))))\n",
        "\n",
        "#Create the training and testing datasets with a 30% training percentage\n",
        "X_train_c, X_test_c, Y_train_c, Y_test_c = train_test_split(x, y, train_size=30/100)\n",
        "clf_c = DecisionTreeClassifier(criterion='gini', max_depth=2)\n",
        "clf_c.fit(X_train_c, Y_train_c)\n",
        "print('Training Accuracy (%) for 30/70 split: ',(100*(clf_c.score(X_train,Y_train))))"
      ],
      "metadata": {
        "id": "E6J1jAoBBwLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rerun the code above a few times to see how the results change.\n",
        "\n",
        "Our Decision Tree's training accuracy is always around 98-99%, regardless of the split percentage we use. While this is a little high, we'll have to see how it performs with the testing data to make a final call."
      ],
      "metadata": {
        "id": "gKLO2fcoDe02"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkrDKDZUQ7EU"
      },
      "source": [
        "Now that we have trained our model, we can see which features it is using to make predictions. \n",
        "\n",
        "Run the code below to visualize the tree based off of the original 50/50 split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jthDniVbRbgR"
      },
      "outputs": [],
      "source": [
        "#Create a visualization for the decision tree\n",
        "dot_data = tree.export_graphviz(clf, out_file=None,\n",
        "                               feature_names=X_train.columns,\n",
        "                               class_names=unique(Y_train.values, ''),                                \n",
        "                               filled=True, rounded=True,\n",
        "                               special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph\n",
        "\n",
        "#did not use inclination -> is transit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K1mpky-7qmC"
      },
      "source": [
        "### **Step 6:** Test the model\n",
        "\n",
        "Run this code block to run the other half of our data (the testing dataset) through the model we just trained to find out how accurate it is with new data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8BugqKW8Ika",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e94e5d7-c6c6-4a2b-93e1-cddf3bd82caa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage accuracy:  99.14221218961626\n"
          ]
        }
      ],
      "source": [
        "#Make the prediction using the model\n",
        "Y_pred = clf.predict(X_test)\n",
        "\n",
        "print('Percentage accuracy: ', 100*accuracy_score(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our decision tree was more accurate in classifying the testing data than the training data. That's a good sign that we didn't overfit it to the training data.\n",
        "\n"
      ],
      "metadata": {
        "id": "LZgL_fA0Hac6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 7:** Evaluate the model\n",
        "\n",
        "Let's evaluate the model with an imaginary exoplanet to see how it performs and what we can learn from it.\n",
        "\n",
        "Consider AMNH-01, a newly discovered exoplanet that was found orbiting the star AMNH in the UWS galaxy. AMNH-01 was discovered using the Transit method.\n",
        "\n",
        "Based on your Decision Tree visualized above, what can you predict about AMNH-01?"
      ],
      "metadata": {
        "id": "n8jS1TnWHrq7"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "D9PTyURgxr9G",
        "88xxnr1lx1nh",
        "CmBl1jdgEE2-",
        "CKtcxO4hEeoR",
        "bts3jKENKK4O",
        "rZ7zIvD6Ln0o",
        "vJdwTahuMTKp",
        "NnsGTrCBMWrZ",
        "qTB4_LUPiY_J",
        "hBJh7Abmg9K-",
        "bg2J0IMzQMdr",
        "t6IFsuz-hkhc",
        "K63jPXpihkhm",
        "CAWF0-GJhkhm",
        "7ahGANG2hkhn",
        "fxByzmDshkho",
        "L4yPVX6VmTAM",
        "r2GQIyxKmTAO",
        "lLkpNVLZxgA2"
      ],
      "name": "Decision_Trees_Exoplanets.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}