{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "K-means_exoplanets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielleRab/SRMPmachine/blob/main/K_means_exoplanets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg16fWNG_ioj"
      },
      "source": [
        "---\n",
        "\n",
        "# **Classifying exoplanets with k-means clustering** \n",
        "\n",
        "### **Step 1:** Identify your question\n",
        "\n",
        "Over 4200 exoplanets have been detected so far, and they vary widely in characteristics. \n",
        "\n",
        "Using Jupiter as a reference point, we will investigate how similar all known exoplanets are to Jupiter, and whether or not we classify them based on that similarity using machine learning.\n",
        "\n",
        "We will form groups of exoplanets based on their characteristic features, where most similar planets will be grouped together. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2:** Select your data\n",
        "\n",
        "The dataset for this activity came from the NASA Exoplanet Archive and is a composite of data from several different sources.\n",
        "\n",
        "We will be looking at a number of features of exoplanets. As a reminder, here is a definition of each column in the dataset:\n",
        "\n",
        "*   pl_name: Planet Name\n",
        "*   discoverymethod: Discovery Method\n",
        "*   disc_year: Discovery Year\n",
        "*   pl_orbper:      Orbital Period [days]\n",
        "*   pl_orbsmax:     Orbit Semi-Major Axis [au]\n",
        "*   pl_radj:        Planet Radius [Jupiter Radius]\n",
        "*   pl_bmassj:      Planet Mass or Mass*sin(i) [Jupiter Mass]\n",
        "*   pl_bmassprov:   Planet Mass or Mass*sin(i) Provenance\n",
        "*   st_teff:        Stellar Effective Temperature [K]\n",
        "*   st_rad:         Stellar Radius [Solar Radius]\n",
        "*   st_mass:        Stellar Mass [Solar mass]\n",
        "*   sy_dist:        Distance [pc]\n",
        "\n",
        "Let's load the data into the colab and take a look. Run the cell below to create a dataframe (table) of our data and preview the first five rows:"
      ],
      "metadata": {
        "id": "6Ky2rGZ5515S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary Python libraries\n",
        "import pandas as pd\n",
        "\n",
        "# create a dataframe called \"df\" with the dataset\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/GabrielleRab/SRMPmachine/main/datasets/exoplanets_cleaned.csv\")\n",
        "\n",
        "# preview the first five rows\n",
        "df.head()"
      ],
      "metadata": {
        "id": "3l3JLv18DaDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be focusing on the pl_orbper (orbital period, or how long it takes the exoplanet to orbit its star in days) and pl_massj (exoplanet mass relative to Jupiter)\n",
        "\n",
        "Run the code below to find out how many rows are in our dataset. Each row represents an exoplanet that has been identified."
      ],
      "metadata": {
        "id": "evSD3K7g6Rzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# return the number of rows in the dataset\n",
        "len(df)"
      ],
      "metadata": {
        "id": "luhOLoOb7lxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3:** Choose your method\n",
        "\n",
        "We will use k-means clustering to determine the main types of exoplanets, relative to Jupiter. This is an unsupervised method because we do not have any exoplanets that we have already classified (or put another way, we have unlabeled data). K-means clustering is an algorithm used to group unlabelled datasets based on their feature similarities. \n",
        "\n",
        "Run the code below to import the necessary Python libraries for k-means clustering."
      ],
      "metadata": {
        "id": "cDBL042e7n34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary Python libraries\n",
        "import pylab as plt\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "import matplotlib.pyplot as mplt \n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "9RI8ndED8qhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 4:** Prepare your data\n",
        "\n"
      ],
      "metadata": {
        "id": "xMXAX4kSNQV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset has some missing values of pl_orbper or pl_massj\\. Run the code below to remove any rows with missing values in pl_orbper or pl_massj. We can do this because we will not be able to analyze any exoplanet without both a calculated orbital period and mass. We do not need to remove exoplanets with other missing values because those values are not relevant for our analysis and by removing them we might remove some exoplanets that we can analyze. "
      ],
      "metadata": {
        "id": "BGZGl7MNNWhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove rows with missing values\n",
        "df_clean = df.dropna(subset=['pl_orbper', 'pl_bmassj'])"
      ],
      "metadata": {
        "id": "fhgyiVp1fJKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how many exoplanets are left in our dataset from the initial 4925."
      ],
      "metadata": {
        "id": "ch3v71Jq9nq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# return the number of rows in the dataset\n",
        "len(df_clean)"
      ],
      "metadata": {
        "id": "C3h54Ti69m6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do you think some exoplanets are missing values for orbital period and mass? How can you check to see how many were removed?"
      ],
      "metadata": {
        "id": "d0Nhojz690vc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now run the code below to select only the columns we wish to include in our analysis"
      ],
      "metadata": {
        "id": "pmQo1r_uNebL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe with only the orbital period and mass\n",
        "x = df_clean.iloc[:, [3,6]].values"
      ],
      "metadata": {
        "id": "G8IQRCE4Nem7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's examine the distribution of pl_orber and pl_bmassj to examine the data distrubiton. "
      ],
      "metadata": {
        "id": "RuYPH8Uvby2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.boxplot(x[:, 0])\n",
        "fig, axs = plt.subplots(2, figsize = (10,4))\n",
        "plt1 = sns.boxplot(x[:, 0], ax = axs[0])\n",
        "plt2 = sns.boxplot(x[:, 1], ax = axs[1])\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "Xqt7fvYzuT62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bias Alert!** There seem to be many outliers in both variables which can influence the results of the k-mean model, which is a model that is very sensitive to outliers. Let's remove the outliers and clean the dataset."
      ],
      "metadata": {
        "id": "mnzE7FC0brbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove outliers\n",
        "#99.7% of the data points lie between +/- 3 standard deviation. If data lies outside this range, it is usually considered an outlier. \n",
        "x_clean = x[(np.abs(stats.zscore(x)) < 3).all(axis=1)]\n",
        "x_clean.size"
      ],
      "metadata": {
        "id": "CSM3IL88bAM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the boxplots again to examine the distribution of the dataset when the worst outliers are removed. "
      ],
      "metadata": {
        "id": "TFWg6M6QAGPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.boxplot(x_clean[:, 0])\n",
        "fig, axs = plt.subplots(2, figsize = (10,4))\n",
        "plt1 = sns.boxplot(x_clean[:, 0], ax = axs[0])\n",
        "plt2 = sns.boxplot(x_clean[:, 1], ax = axs[1])\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "_0OBYwAS_5bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the overall distribution of our data:"
      ],
      "metadata": {
        "id": "KCb2iIlvnWyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot distribution\n",
        "sns.distplot(x_clean)"
      ],
      "metadata": {
        "id": "bvDUIfBu6zbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bias Alert!** Our data is left-skewed. (statistical bias) This means that most of our data is in the lower end of our data range with only a few data points at the higher end of the range. "
      ],
      "metadata": {
        "id": "k_V7Pl5zCgP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the log transformed values of our variables to see if that improves the distribution. "
      ],
      "metadata": {
        "id": "wN-No3l5DtJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scale the data using log10\n",
        "logx =  np.log10(x)\n",
        "\n",
        "# plot the distribution\n",
        "sns.distplot(logx)"
      ],
      "metadata": {
        "id": "C_4qk06f6ybf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By doing a log transofrmation of our data, we have created a less skewed distribution of our dataset. The log scaled values sometimes yield negative values. These indicate negative powers, and not negative values of the variables themselves. "
      ],
      "metadata": {
        "id": "Ow53v2LwDTg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 5:** Create and Use the model\n",
        "\n",
        "Now it's time to make our k-means classifier. We will also need to set the hyperparameters (values that control how the model learns and makes decisions). In this case we will specify the number of clusters as 3.\n",
        "\n",
        "**Note:** Because k-means clustering is an unsupervised method, we do not need to split our data into a training and a testing set. No data is labeled, so there is no way to train the model.\n",
        "\n",
        "Run the code below to create the model:"
      ],
      "metadata": {
        "id": "hg2O6Ty-Mp9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To calculate the optimum value of k (number of clusters) in the k-means model, we draw an elbow curve to see where the steep decline happens. "
      ],
      "metadata": {
        "id": "gjsk2aWFuMf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distorsions = []\n",
        "for k in range(1, 10):\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    kmeans.fit(logx)\n",
        "    distorsions.append(kmeans.inertia_)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "plt.plot(range(1, 10), distorsions)\n",
        "plt.grid(True)\n",
        "plt.title('Elbow curve')"
      ],
      "metadata": {
        "id": "sk_puoTHtu9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like 3 is the optimum value of k, so we will specify 3 clusters when we create our model:"
      ],
      "metadata": {
        "id": "qIhZ2X6OuVOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the k-means classifier\n",
        "kmeans = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n"
      ],
      "metadata": {
        "id": "F8Z877SLNSx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bias Alert!** Since we have a pre-specified k of 3, our k-means classifier may cluster non-clustered data. Especially at the borders of clusters, points that are basically toss-ups may be put into one cluster or another. This may especially be a problem if the clusters are very close together. Visualizing the clusters can help us evaluate this risk.\n",
        "\n",
        "Next we will apply the model to the data:"
      ],
      "metadata": {
        "id": "cxZowIOUOjmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model to the data\n",
        "y_kmeans = kmeans.fit_predict(logx)"
      ],
      "metadata": {
        "id": "GNVwoVZlOkAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute the size of each cluster that our model formed. "
      ],
      "metadata": {
        "id": "vvW2VSaAG5sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sizes of each cluster \n",
        "print(logx[y_kmeans == 0].size)\n",
        "print(logx[y_kmeans == 1].size)\n",
        "print(logx[y_kmeans == 2].size)\n"
      ],
      "metadata": {
        "id": "L7qtLbxKG0n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bias Alert!** One cluster is significantly bigger than the other two. This might introduce some inaccuracy in our clustering. K-means clustering will always form clusters of similar areas, but different clusters may have different densities. This might be a problem if one category of exoplanets has many more exoplanets than the others; some of them (especially the outliers) may end up in another cluster. "
      ],
      "metadata": {
        "id": "b7d5PzlkG_bz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize the clusters that our model has created. We will add the planets from our solar system for reference:"
      ],
      "metadata": {
        "id": "fyN77EAqW0Lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "font = {'family' : 'normal',\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 22}\n",
        "\n",
        "#Visualising the clusters\n",
        "plt.scatter(logx[y_kmeans == 0, 0], logx[y_kmeans == 0, 1], s = 20, c = 'purple', label = 'Hot Jupiters')\n",
        "plt.scatter(logx[y_kmeans == 1, 0], logx[y_kmeans == 1, 1], s = 20, c = 'blue', label = 'Non-giants')\n",
        "plt.scatter(logx[y_kmeans == 2, 0], logx[y_kmeans == 2, 1], s = 20, c = 'orange', label = 'Long Period Giants')\n",
        "\n",
        "#Plotting the centroids of the clusters\n",
        "# print(kmeans.cluster_centers_)\n",
        "plt.scatter(\n",
        "    kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
        "    s=100, marker='*',\n",
        "    c='black', \n",
        "    label='centroids'\n",
        ")\n",
        "\n",
        "plt.xlabel('Orbital Period (days) ')\n",
        "plt.ylabel('Mass/Mass_J')\n",
        "plt.legend()\n",
        "plt.rcParams[\"figure.figsize\"] = (12,8)\n"
      ],
      "metadata": {
        "id": "jthDniVbRbgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bias alert!** Looking at these three clusters, there is no space between them meaning that the borders between clusters may be somewhat arbitrary. Points along the borders should be considered with caution.\n",
        "\n",
        "That said, we can learn something interesting about how exoplanets relate to Jupiter based on these results. The three clusters may be described as follows:\n",
        "\n",
        "**Hot Jupiters**: A Jupiter-like planet in terms of mass and radius, but typically found closer to its host star than Jupiter is to the sun. A period of orbit being only 3 days.\n",
        "\n",
        "**Long period giants**: \"Cold Jupiters\". Giant planets of a similar mass to Jupiter, located further out in their orbits than Hot Jupiters. A period of orbit of greater than 100 days.\n",
        "\n",
        "**Non-giants**: Everything else\n",
        "\n",
        "\n",
        "*Questions for reflection:*\n",
        "\n",
        "What do you notice about where our solar system's planets are relative to the observed exoplanets? \n",
        "\n",
        "Can you explain what you see based on what you know about exoplanet discovery methods?"
      ],
      "metadata": {
        "id": "xpsINcY8jv9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make a plot of our own solar system planets that we know the location for. Note that we also applied a log transformation to the planets' locations to keep them consistent with the exoplanets' plot. \n"
      ],
      "metadata": {
        "id": "hSpJsnkYGNDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for solar system planets\n",
        "solars_x = [88, 224.7, 365.2, 687, 4331, 10747, 30589, 59800]\n",
        "logplanets_x = np.array(np.log10(solars_x)) \n",
        "solars_y = [.00017, .00256, .00315, .00034, 1, .299, .046, .054]\n",
        "logplanets_y = np.array(np.log10(solars_y))\n",
        "\n",
        "# plotting the solar planets\n",
        "labels = [\"Mercury\", \"Venus\", \"Earth\", \"Mars\", \"Jupiter\", \"Saturn\", \"Uranus\", \"Neptune\"]\n",
        "colors = [\"green\", \"yellow\", \"lightblue\", \"magenta\", \"red\", \"pink\", \"turquoise\", \"grey\"]\n",
        "for c, i in enumerate(logplanets_x):\n",
        "  plt.text(i, logplanets_y[c], labels[c])\n",
        "plt.scatter(logplanets_x, logplanets_y, s = 20, c = colors)\n",
        "plt.rcParams[\"figure.figsize\"] = (6,4)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "A2IcrGDIGeta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Where would these planets lie in the exoplanets clusters formed? Let's overlap these plots to explore that! "
      ],
      "metadata": {
        "id": "aRj_G2Pun5Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualising the clusters\n",
        "plt.scatter(logx[y_kmeans == 0, 0], logx[y_kmeans == 0, 1], s = 20, c = 'purple', label = 'Hot Jupiters')\n",
        "plt.scatter(logx[y_kmeans == 1, 0], logx[y_kmeans == 1, 1], s = 20, c = 'blue', label = 'Non-giants')\n",
        "plt.scatter(logx[y_kmeans == 2, 0], logx[y_kmeans == 2, 1], s = 20, c = 'orange', label = 'Long Period Giants')\n",
        "\n",
        "#Plotting the centroids of the clusters\n",
        "# print(kmeans.cluster_centers_)\n",
        "plt.scatter(\n",
        "    kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
        "    s=100, marker='*',\n",
        "    c='black', \n",
        "    label='centroids'\n",
        ")\n",
        "\n",
        "# #Adding our solar system's planets for comparison\n",
        "# #Adding a log transformation to keep it consistent with the expolanets plot\n",
        "planets_x = [88, 224.7, 365.2, 687, 4331, 10747, 30589, 59800]\n",
        "logplanets_x = np.array(np.log10(planets_x)) \n",
        "planets_y = [.00017, .00256, .00315, .00034, 1, .299, .046, .054]\n",
        "logplanets_y = np.array(np.log10(planets_y))\n",
        "\n",
        "labels = [\"Mercury\", \"Venus\", \"Earth\", \"Mars\", \"Jupiter\", \"Saturn\", \"Uranus\", \"Neptune\"]\n",
        "colors = [\"green\", \"yellow\", \"lightblue\", \"magenta\", \"red\", \"pink\", \"turquoise\", \"grey\"]\n",
        "for c, i in enumerate(logplanets_x):\n",
        "  plt.text(i, logplanets_y[c], labels[c])\n",
        "plt.scatter(logplanets_x, logplanets_y, s = 20, c = colors)\n",
        "\n",
        "plt.xlabel('Orbital Period (days) ')\n",
        "plt.ylabel('Mass/Mass_J')\n",
        "plt.legend()\n",
        "plt.rcParams[\"figure.figsize\"] = (12,8)\n"
      ],
      "metadata": {
        "id": "tXPGlan5rPNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discuss with a partner: does it make sense that only Jupiter is close to one of the three clusters? Why do you think our data is distributed the way it is?"
      ],
      "metadata": {
        "id": "GW3bux2yCg7s"
      }
    }
  ]
}