{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielleRab/SRMPmachine/blob/main/Decision_Trees_Dragonflies_location.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg16fWNG_ioj"
      },
      "source": [
        "# **Exploring Dragonfly wings with Decision Trees**\n",
        "\n",
        "### **Step 1:** Identify your question\n",
        "\n",
        "In this colab, you will build a machine learning model to figure out which characteristics of a dragonfly's wing are best correlated with its location (in North America or outside of North America)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEVDmRuIDesI"
      },
      "source": [
        "### **Step 2:** Select your data\n",
        "This dataset contains wing measurements from a series of dragonfly specimens collected around the world.\n",
        "\n",
        "![Dragonfly](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQEBt2Q-q8f4RA4x0vo4bRPw6w3_mSshyaUiHXO8cR52CfDW419Vjy_0-CfiRohgVqiWWE&usqp=CAU)\n",
        "\n",
        "The measurements include:\n",
        "*   Area of each hindwing (HW) and forewing (FW) in mm^2\n",
        "*   Inner and outer length and width of each wing (in mm)\n",
        "*   Widest ratio: Ratio of distance (in pixels) from the base of the wing to its thickest portion to wing length (in pixels)\n",
        "*   Slope of thickness: Slope of line that best fits a plot of wing thickness (in pixels), measured along the length of the wing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_CkpMjbxtmX"
      },
      "source": [
        "Let's load the data into the colab and take a look. Run the cell below to create a dataframe (table) of our data and preview the first five rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l3JLv18DaDg"
      },
      "outputs": [],
      "source": [
        "# import the necessary Python libraries\n",
        "import pandas as pd\n",
        "\n",
        "# create a dataframe called \"df\" with the dataset\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/GabrielleRab/SRMPmachine/main/datasets/wing_measurements_location.csv\")\n",
        "df['North_America'] = df['North_America'].map({True: 'True', False: 'False'})\n",
        "\n",
        "# preview the first five rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8tqBQAhzy73"
      },
      "source": [
        "Let's find out how many rows are in our dataset. Each row represents a dragonfly specimen that has been collected.\n",
        "\n",
        "Type len(df) below and run the cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8rP0ExL5zxnt"
      },
      "outputs": [],
      "source": [
        "# return the number of rows in the dataset. Type len(df) below and run the cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DO64X0aET2F"
      },
      "source": [
        "### **Step 3:** Choose your method\n",
        "\n",
        "We will be using the Decision Tree method today, as it is a good fit for categorizing labeled data.\n",
        "\n",
        "Run the code below to import the necessary Python libraries for creating Decision Trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W7BtJ4Td0qlQ"
      },
      "outputs": [],
      "source": [
        "#import necessary Python libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import graphviz\n",
        "from numpy.ma.extras import unique\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQd76u9wbIoO"
      },
      "source": [
        "### **Step 4:** Prepare your data\n",
        "\n",
        "Decision Trees work best when the features being analyzed are numerical. Aside from our labels (\"North_America\": True or False), there are several other columns with non-numerical data or unnecessary information (Collection ID). We will remove those now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoYfvbw4cUOa"
      },
      "outputs": [],
      "source": [
        "#We will remove columns we don't need for this investigation\n",
        "df = df.drop('Collection Unique ID', 1)\n",
        "df = df.drop('Suborder', 1)\n",
        "df = df.drop('Species name', 1)\n",
        "\n",
        "#Return the first 5 rows of the dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try it yourself! We only want to look at data formatted like numbers, so we will remove the Family column. Type df = df.drop('Family', 1) in the cell below and press play to run your code.\n",
        "\n",
        "Check to make sure that the Family column is gone."
      ],
      "metadata": {
        "id": "tJ7Tpfspw7fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Type df = df.drop('Family', 1) below to remove the 'Family' column.\n",
        "\n",
        "\n",
        "#Return the first 5 rows of the dataframe\n",
        "df.head()"
      ],
      "metadata": {
        "id": "w0yKcH82w2RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep52vMKU3OqZ"
      },
      "source": [
        "When people collect data by hand, there are likely to be some missing values. Let's remove all of the rows with missing data. Run the code below to do so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k-o6tx7Ndv2Z"
      },
      "outputs": [],
      "source": [
        "#Remove any rows with missing values\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how many rows are left. Type len(df) below and run the code:"
      ],
      "metadata": {
        "id": "cK6HLdWY1mKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Return the remaining number of rows. Type len(df) below and run code:\n",
        "\n"
      ],
      "metadata": {
        "id": "7AgTR8kZ1lCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvu0MXEF6TKR"
      },
      "source": [
        "Now that our dataset is ready, let's check it for balance. Are there the same number of dragonflies in North America and outside of North America? Run the code below to find out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJCwwfWOeovg"
      },
      "outputs": [],
      "source": [
        "#Return the number of rows with either Radial Velocity or Transit for discovery method\n",
        "print(\"In North America:\",len(df[df.North_America == 'True']))\n",
        "print(\"Not in North America:\",len(df[df.North_America == 'False']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMMJgjEm6jPA"
      },
      "source": [
        "As it turns out, there are significantly more dragonflies in North America than not in North America.\n",
        "\n",
        "**Bias Alert:** This introduces a possible source of statistical bias into our analysis. Our decision tree may end up better prepared to identify North American dragonflies because it has more information about them.\n",
        "\n",
        "One way to address this source of bias is to ensure that our training and testing data both contain enough specimens from each location. Another is to make sure that we have a large enough training dataset to include sufficient non-North American specimens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC0k603a8n7R"
      },
      "source": [
        "Now it's time to split our data into a training and a testing dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bias Alert:** It's important to create a random split to eliminate any clustering or sorting of the data. Run the code below to do so:"
      ],
      "metadata": {
        "id": "2wQpoLZG_7vn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data 50/50 into a training and testing set by typing the number 50 after \"training_percentage =\" below. Then run the code cell."
      ],
      "metadata": {
        "id": "q6vCfSJmnyI9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mfNcjA8rLWbe"
      },
      "outputs": [],
      "source": [
        "#Get the features and labels from the data\n",
        "x = df.drop(['North_America'], axis=1)\n",
        "y = df['North_America']\n",
        "\n",
        "#Specify a 50% split: TYPE 50 AFTER THE EQUAL SIGN BELOW\n",
        "training_percentage =\n",
        "\n",
        "#Create the training and testing datasets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, train_size=training_percentage/100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg2O6Ty-Mp9G"
      },
      "source": [
        "### **Step 5:** Train the model\n",
        "\n",
        "Now it's time to make our decision tree. We will also need to set the hyperparameters (values that control how the model learns and makes decisions). In this case we will specify the maximum depth and the criterion the model will use to evaluate each feature.\n",
        "\n",
        "The \"Gini index\" is a measure of how pure the split is for each node in the Decision Tree. A lower Gini index indicates a more pure split.\n",
        "\n",
        "Type the number 2 after \"max_depth= \" below and then run the code cell to create your model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F8Z877SLNSx3"
      },
      "outputs": [],
      "source": [
        "#Create a decision tree classifier called \"clf\"\n",
        "# TYPE 2 AFTER \"MAX_DEPTH= \" BELOW\n",
        "clf = DecisionTreeClassifier(criterion='gini', max_depth= , random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxZowIOUOjmj"
      },
      "source": [
        "Now that we have created a decision tree it's time to train it using our training dataset. We will also evaluate the model's accuracy (what percent of dragonflies did it correctly classify based on where they were collected).\n",
        "\n",
        "Run the code below to train and evaluate our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNVwoVZlOkAU"
      },
      "outputs": [],
      "source": [
        "#Train the model\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "#Print the training accuracy\n",
        "print('\\nTraining Accuracy (%): ',(100*(clf.score(X_train,Y_train))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bias alert:** Because our training accuracy is so high, we run the risk of overfitting our model. This means it might be better at predicting the training data than the testing data.\n",
        "\n",
        "We can try to address this by training the model with a few different split percentages (instead of a 50/50 train/test split). Run the code below to see how they compare:"
      ],
      "metadata": {
        "id": "ooIT8KM9BbHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train and test the model with a 40% training percentage\n",
        "X_train_b, X_test_b, Y_train_b, Y_test_b = train_test_split(x, y, train_size=40/100)\n",
        "clf_b = DecisionTreeClassifier(criterion='gini', max_depth=2)\n",
        "clf_b.fit(X_train, Y_train)\n",
        "print('Training Accuracy (%) for 40/60 split: ',(100*(clf_b.score(X_train_b,Y_train_b))))\n",
        "\n",
        "#Create the training and testing datasets with a 30% training percentage\n",
        "X_train_c, X_test_c, Y_train_c, Y_test_c = train_test_split(x, y, train_size=30/100)\n",
        "clf_c = DecisionTreeClassifier(criterion='gini', max_depth=2)\n",
        "clf_c.fit(X_train_c, Y_train_c)\n",
        "print('Training Accuracy (%) for 30/70 split: ',(100*(clf_c.score(X_train,Y_train))))"
      ],
      "metadata": {
        "id": "E6J1jAoBBwLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rerun the code above a few times to see how the results change.\n",
        "\n",
        "Our Decision Tree's training accuracy is always around 90%, regardless of the split percentage we use."
      ],
      "metadata": {
        "id": "gKLO2fcoDe02"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkrDKDZUQ7EU"
      },
      "source": [
        "Now that we have trained our model, we can see which features it is using to make predictions.\n",
        "\n",
        "Run the code below to visualize the tree based off of the original 50/50 split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jthDniVbRbgR"
      },
      "outputs": [],
      "source": [
        "#Create a visualization for the decision tree\n",
        "dot_data = tree.export_graphviz(clf, out_file=None,\n",
        "                               feature_names=X_train.columns,\n",
        "                               class_names=unique(Y_train.values, ''),\n",
        "                               filled=True, rounded=True,\n",
        "                               special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: \"True\" means found in North America and \"False\" means not found in North America"
      ],
      "metadata": {
        "id": "OKlYKIu0RUqe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K1mpky-7qmC"
      },
      "source": [
        "### **Step 6:** Test the model\n",
        "\n",
        "Run this code block to run the other half of our data (the testing dataset) through the model we just trained to find out how accurate it is with new data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8BugqKW8Ika"
      },
      "outputs": [],
      "source": [
        "#Make the prediction using the model\n",
        "Y_pred = clf.predict(X_test)\n",
        "\n",
        "print('Percentage accuracy: ', 100*accuracy_score(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bias alert:** It's important to check if your decision tree is more or less accurate in classifying the training data than the testing data. If it is more accurate in the training vs testing data your model may be overfit.\n",
        "\n",
        "Compare the accuracy in the training vs testing step. Is our model overfit?"
      ],
      "metadata": {
        "id": "LZgL_fA0Hac6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 7:** Evaluate the model\n",
        "\n",
        "Let's apply the model we just made to some newly identified dragonflies!\n",
        "\n",
        "Look at the data for four dragonflies and see if our model would classify them correctly:\n",
        "[New dragonfly records](https://docs.google.com/spreadsheets/d/1qt-X0ylXl8HSzL_rYrMPLANudCJAmSIa-uZKZQLITfU/edit?usp=sharing)\n",
        "\n",
        "Follow the decision tree above to find out! For example, if the tree says \"Slope of thickness FW ≤ 0.069\" and the dragonfly has a \"Slope of thickness FW\" of 0.05, you should follow the \"True\" arrow because it is true that this dragonfly's forewing Slope of thickness is less than 0.069.\n",
        "\n",
        "Did the model get all four dragonflies right? Did anything about this result surprise you? Why or why not?"
      ],
      "metadata": {
        "id": "SJwl-pGHnyAH"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "D9PTyURgxr9G",
        "88xxnr1lx1nh",
        "CmBl1jdgEE2-",
        "CKtcxO4hEeoR",
        "bts3jKENKK4O",
        "rZ7zIvD6Ln0o",
        "vJdwTahuMTKp",
        "NnsGTrCBMWrZ",
        "qTB4_LUPiY_J",
        "hBJh7Abmg9K-",
        "bg2J0IMzQMdr",
        "t6IFsuz-hkhc",
        "K63jPXpihkhm",
        "CAWF0-GJhkhm",
        "7ahGANG2hkhn",
        "fxByzmDshkho",
        "L4yPVX6VmTAM",
        "r2GQIyxKmTAO",
        "lLkpNVLZxgA2"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}